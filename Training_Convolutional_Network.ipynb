{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Convolutional Neural Network\n",
    "\n",
    "\n",
    "In this notebook we will train a convolutional neural network with the Zalando dataset (images of clothes). Let's start by preparing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = [\"T-Shirt\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"]\n",
    "\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#We have to reshape in order to add the color channel. The other dimensions remain the same\n",
    "\n",
    "x_train = x_train.reshape((len(x_train),x_train[0].shape[0],x_train[0].shape[1],1))\n",
    "x_test = x_test.reshape((len(x_test),x_test[0].shape[0],x_test[0].shape[1],1))\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the neural network (same code we had in `Convolutional_Neural_Network` notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(5,5), activation=\"relu\", #convolutional layer of 32 filters and 5x5 windows. Activation function is relu\n",
    "         input_shape=(28,28,1))) #we already specify input shape. Images are black and white, so we only have one color channel\n",
    "model.add(MaxPooling2D(2,2)) #pooling with 2x2 window\n",
    "model.add(Conv2D(64,(5,5), activation=\"relu\")) #remember that we only need to specify the input shape in the first layer\n",
    "model.add(MaxPooling2D(2,2)) #pooling with 2x2 window\n",
    "model.add(Flatten()) #remember that we need to flatten the 3D tensor to 1D in order to use a densely connected neural network\n",
    "model.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, bear in mind that we have **not** changed our labels to categoricals. This is because we will use `sparse_categorical_crossentropy`as a loss function. This is, in essence, the same as `categorical_crossentropy`, but it allows as to use labels as a sequence of integers rather than in a one-hot encoded form (for more information,check https://www.dlology.com/blog/how-to-use-keras-sparse_categorical_crossentropy/. Keras documentation also available).\n",
    "\n",
    "\n",
    "Now that we have explained this, it is time to train the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 1.1889 - accuracy: 0.5882\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.5367 - accuracy: 0.8054\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.4666 - accuracy: 0.8344\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.4224 - accuracy: 0.8513\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.3966 - accuracy: 0.8580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28d45ff56c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy']) #here we apply new loss function\n",
    "\n",
    "model.fit(x_train,y_train,epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4605 - accuracy: 0.8313\n",
      "Test accuracy 0.8313000202178955\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model.evaluate(x_test,y_test)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, one epoch with this neural network requires significantly more time than with a basic one. However, you can see that we obtain much better results (83% compared to 76% with a basic network).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the neural network\n",
    "\n",
    "\n",
    "Maybe we can get even better results if we add more filters to the convolutional networks and a second densely connected neural network before the last one. Apart from this, we can also use padding in the convolutional layers. Remember that padding allows us to maintain the dimensionality of the outputs. In order to do this, we must add the parameter `padding=\"same\"` in each convolutional layer we would like to be padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,(5,5), activation=\"relu\",padding=\"same\", #padding added\n",
    "         input_shape=(28,28,1))) \n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(64,(5,5), activation=\"relu\",padding=\"same\")) \n",
    "model.add(MaxPooling2D(2,2)) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's have a look at the summary to check that the outputs have the same dimension as the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 305,546\n",
      "Trainable params: 305,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the first layer maintains the (28,28) shape of the input (before padding the output became a 24x24 matrix), while the second one has a (14,14) shape (pooling halved each dimension)\n",
    "\n",
    "\n",
    "Let's train the model. It will take even more time than before, so you can let the code run and go grab a cup of tea/coffee :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 101s 54ms/step - loss: 1.0909 - accuracy: 0.6271\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 158s 84ms/step - loss: 0.5040 - accuracy: 0.8173s - loss: 0.504\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 255s 136ms/step - loss: 0.4253 - accuracy: 0.8468\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 211s 113ms/step - loss: 0.3854 - accuracy: 0.8617\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 197s 105ms/step - loss: 0.3541 - accuracy: 0.8728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28d4614ccc8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy']) #here we apply new loss function\n",
    "\n",
    "model.fit(x_train,y_train,epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3553 - accuracy: 0.8730\n",
      "Test accuracy 0.8730000257492065\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model.evaluate(x_test,y_test)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as we should have expected, we obtain even better results. However, this is not the best we can do, but we will leave it for the next notebook `Improving_Convolutional_Neural_Network`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
